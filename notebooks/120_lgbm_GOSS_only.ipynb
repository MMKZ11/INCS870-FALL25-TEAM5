{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "UNpJJWv5gQ11",
        "outputId": "39e89d45-8bcf-45c1-ab74-5c983c3c0644"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/ciciot2023_subset.parquet'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3229714653.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mDATA_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/ciciot2023_subset.parquet\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;34m\"label\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"需要一列 label\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loaded:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"classes:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0mcheck_dtype_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m     return impl.read(\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mto_pandas_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"split_blocks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         path_or_handle, handles, filesystem = _get_path_or_handle(\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mfilesystem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m# fsspec resources can also point to directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         handles = get_handle(\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/ciciot2023_subset.parquet'"
          ]
        }
      ],
      "source": [
        "# Execute only once when stock is miss\n",
        "# !pip -q install lightgbm scikit-learn pandas numpy matplotlib pyarrow\n",
        "import os, time, json\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import (\n",
        "    f1_score, classification_report, confusion_matrix, precision_recall_fscore_support\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 结果目录\n",
        "Path(\"results/logs\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"results/figures\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"results/tables\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def per_class_recall(y_true, y_pred):\n",
        "    # 返回一个 {class_id: recall} 的 dict\n",
        "    p, r, f, s = precision_recall_fscore_support(y_true, y_pred, average=None, zero_division=0)\n",
        "    return {int(i): float(r[i]) for i in range(len(r))}\n",
        "\n",
        "def plot_recall_bar(rec_dict, class_names, title, save_path=None):\n",
        "    idx = list(rec_dict.keys())\n",
        "    vals = [rec_dict[i] for i in idx]\n",
        "    names = [class_names[i] for i in idx]\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.bar(range(len(vals)), vals)\n",
        "    plt.xticks(range(len(vals)), names, rotation=45, ha='right')\n",
        "    plt.ylim(0,1)\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=150)\n",
        "    plt.show()\n",
        "# === 修改这里：你的 parquet 路径 ===\n",
        "DATA_PATH = \"data/ciciot2023_subset.parquet\"\n",
        "\n",
        "df = pd.read_parquet(DATA_PATH)\n",
        "assert \"label\" in df.columns, \"需要一列 label\"\n",
        "print(\"Loaded:\", df.shape, \"classes:\", df[\"label\"].nunique())\n",
        "print(df[\"label\"].value_counts().head())\n",
        "\n",
        "# 标签编码\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(df[\"label\"])\n",
        "class_names = list(le.classes_)\n",
        "\n",
        "# 特征\n",
        "X = df.drop(columns=[\"label\"])\n",
        "\n",
        "# 若还有 object 列，做 one-hot（EFB 对稀疏/互斥特征更有发挥空间）\n",
        "cat_cols = [c for c in X.columns if X[c].dtype == \"object\"]\n",
        "if cat_cols:\n",
        "    X = pd.get_dummies(X, columns=cat_cols, dummy_na=False)\n",
        "\n",
        "M_RAW = X.shape[1]     # 原始维度\n",
        "print(\"M_raw =\", M_RAW)\n",
        "\n",
        "# 切分（先用随机分层；你也可以换成按时间/设备的切分策略）\n",
        "Xtr, Xtmp, ytr, ytmp = train_test_split(X, y, test_size=0.30, stratify=y, random_state=42)\n",
        "Xva, Xte,  yva, yte  = train_test_split(Xtmp, ytmp, test_size=0.50, stratify=ytmp, random_state=42)\n",
        "\n",
        "print(\"Train/Val/Test:\", Xtr.shape, Xva.shape, Xte.shape)\n",
        "def train_lgbm(\n",
        "    Xtr, ytr, Xva, yva,\n",
        "    use_goss=False, enable_efb=True, top_rate=0.10, other_rate=0.10,\n",
        "    seed=42, learning_rate=0.05, num_leaves=64, min_data_in_leaf=50,\n",
        "    objective=\"multiclass\", num_class=None\n",
        "):\n",
        "    params = dict(\n",
        "        objective=objective,\n",
        "        metric=[\"multi_logloss\"] if objective==\"multiclass\" else [\"auc\",\"binary_logloss\"],\n",
        "        num_class=num_class if objective==\"multiclass\" else None,\n",
        "        boosting_type=\"goss\" if use_goss else \"gbdt\",\n",
        "        learning_rate=learning_rate,\n",
        "        num_leaves=num_leaves,\n",
        "        min_data_in_leaf=min_data_in_leaf,\n",
        "        max_bin=255,\n",
        "        feature_fraction=1.0,\n",
        "        bagging_fraction=1.0,\n",
        "        lambda_l2=1.0,\n",
        "        enable_bundle=enable_efb,   # EFB 开关\n",
        "        force_col_wise=True,\n",
        "        deterministic=True,\n",
        "        seed=seed,\n",
        "        verbose=-1,\n",
        "    )\n",
        "    if use_goss:\n",
        "        params.update(dict(top_rate=top_rate, other_rate=other_rate))  # GOSS 采样比\n",
        "\n",
        "    dtr = lgb.Dataset(Xtr, ytr, free_raw_data=False)\n",
        "    dva = lgb.Dataset(Xva, yva, reference=dtr, free_raw_data=False)\n",
        "\n",
        "    t0 = time.time()\n",
        "    booster = lgb.train(\n",
        "        params, dtr, num_boost_round=5000,\n",
        "        valid_sets=[dtr, dva], valid_names=[\"train\",\"val\"],\n",
        "        early_stopping_rounds=100, keep_training_booster=True, verbose_eval=50\n",
        "    )\n",
        "    t1 = time.time()\n",
        "    elapsed = t1 - t0\n",
        "\n",
        "    # 评测（验证集）\n",
        "    proba = booster.predict(Xva, num_iteration=booster.best_iteration)\n",
        "    if objective == \"multiclass\":\n",
        "        yhat = proba.argmax(1)\n",
        "        macro_f1 = f1_score(yva, yhat, average=\"macro\")\n",
        "    else:\n",
        "        yhat = (proba >= 0.5).astype(int)\n",
        "        macro_f1 = f1_score(yva, yhat, average=\"binary\")\n",
        "\n",
        "    rec = per_class_recall(yva, yhat)\n",
        "    cm  = confusion_matrix(yva, yhat).tolist()\n",
        "\n",
        "    result = dict(\n",
        "        time_sec=float(elapsed),\n",
        "        best_iter=int(booster.best_iteration),\n",
        "        macro_f1=float(macro_f1),\n",
        "        n_features_input=int(Xtr.shape[1]),\n",
        "        n_features_effective=len(booster.feature_name()), # 观察 EFB 后有效特征数\n",
        "        params=booster.params\n",
        "    )\n",
        "    return booster, result, rec, cm\n",
        "\n",
        "\n",
        "# 120_lgbm_GOSS_only.ipynb\n",
        "USE_GOSS = True\n",
        "ENABLE_EFB = False\n",
        "\n",
        "TOP_RATE   = 0.10   # 只有在 GOSS=True 时生效\n",
        "OTHER_RATE = 0.10\n",
        "\n",
        "OBJECTIVE  = \"multiclass\"       # 如果只做二分类，就改成 \"binary\"\n",
        "NUM_CLASS  = len(np.unique(y))  # 二分类时可以设为 None\n",
        "SETTING_NAME = f\"{'goss' if USE_GOSS else 'gbdt'}_{'EFB' if ENABLE_EFB else 'noEFB'}\"\n",
        "SETTING_NAME\n",
        "booster, result, rec, cm = train_lgbm(\n",
        "    Xtr, ytr, Xva, yva,\n",
        "    use_goss=USE_GOSS,\n",
        "    enable_efb=ENABLE_EFB,\n",
        "    top_rate=TOP_RATE,\n",
        "    other_rate=OTHER_RATE,\n",
        "    objective=OBJECTIVE,\n",
        "    num_class=NUM_CLASS\n",
        ")\n",
        "\n",
        "print(json.dumps({**result, \"setting\": SETTING_NAME}, indent=2))\n",
        "\n",
        "# 保存日志/模型/表格\n",
        "with open(f\"results/logs/{SETTING_NAME}.json\", \"w\") as f:\n",
        "    json.dump({**result, \"setting\": SETTING_NAME, \"per_class_recall\": rec, \"cm\": cm}, f, indent=2)\n",
        "\n",
        "booster.save_model(f\"results/{SETTING_NAME}.txt\")\n",
        "\n",
        "# 汇总到一个 CSV（若不存在则创建）\n",
        "row = {\n",
        "    \"setting\": SETTING_NAME,\n",
        "    \"time_sec\": result[\"time_sec\"],\n",
        "    \"best_iter\": result[\"best_iter\"],\n",
        "    \"macro_f1\": result[\"macro_f1\"],\n",
        "    \"M_raw\": result[\"n_features_input\"],\n",
        "    \"M_effective\": result[\"n_features_effective\"],\n",
        "    \"use_goss\": USE_GOSS,\n",
        "    \"enable_efb\": ENABLE_EFB,\n",
        "    \"top_rate\": TOP_RATE if USE_GOSS else None,\n",
        "    \"other_rate\": OTHER_RATE if USE_GOSS else None\n",
        "}\n",
        "tbl_path = Path(\"results/tables/efb_goss_ablation.csv\")\n",
        "pd.DataFrame([row]).to_csv(tbl_path, mode=\"a\", header=not tbl_path.exists(), index=False)\n",
        "tbl_path\n",
        "# per-class recall 柱状图\n",
        "save_fig = f\"results/figures/recall_{SETTING_NAME}.png\"\n",
        "plot_recall_bar(rec, class_names, f\"Per-class Recall: {SETTING_NAME}\", save_fig)\n",
        "\n",
        "# 更详细的分类报告（验证集）\n",
        "proba = booster.predict(Xva, num_iteration=booster.best_iteration)\n",
        "yhat = proba.argmax(1) if OBJECTIVE==\"multiclass\" else (proba>=0.5).astype(int)\n",
        "print(classification_report(yva, yhat, target_names=class_names, digits=4))"
      ]
    }
  ]
}
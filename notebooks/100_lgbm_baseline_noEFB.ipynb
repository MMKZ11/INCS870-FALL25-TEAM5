{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ========= Mount & IO paths =========\n",
        "import os, pathlib, json, numpy as np, pandas as pd\n",
        "if \"COLAB_RELEASE_TAG\" in os.environ or os.path.exists(\"/content\"):\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        if not os.path.exists(\"/content/drive\"):\n",
        "            drive.mount(\"/content/drive\")\n",
        "    except Exception as e:\n",
        "        print(\"Colab mount skipped:\", e)\n",
        "\n",
        "DATA_DIR = \"/content/drive/MyDrive/INCS870/data\" if os.path.exists(\"/content/drive\") else \"data\"\n",
        "RESULTS  = \"/content/drive/MyDrive/INCS870/results\" if os.path.exists(\"/content/drive\") else \"results\"\n",
        "pathlib.Path(f\"{RESULTS}/logs\").mkdir(parents=True, exist_ok=True)\n",
        "pathlib.Path(f\"{RESULTS}/figures\").mkdir(parents=True, exist_ok=True)\n",
        "pathlib.Path(f\"{RESULTS}/tables\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with open(f\"{DATA_DIR}/ciciot2023_split_meta.json\",\"r\") as f:\n",
        "    meta = json.load(f)\n",
        "class_names = meta[\"class_names\"]\n",
        "OBJECTIVE   = \"multiclass\" if meta[\"task_mode\"]==\"multiclass\" else \"binary\"\n",
        "NUM_CLASS   = len(class_names) if OBJECTIVE==\"multiclass\" else None\n",
        "\n",
        "Xtr = pd.read_parquet(f\"{DATA_DIR}/train.parquet\"); ytr = Xtr.pop(\"label\").values\n",
        "Xva = pd.read_parquet(f\"{DATA_DIR}/val.parquet\");   yva = Xva.pop(\"label\").values\n",
        "Xte = pd.read_parquet(f\"{DATA_DIR}/test.parquet\");  yte = Xte.pop(\"label\").values\n",
        "\n",
        "M_RAW = Xtr.shape[1]; print(\"M_raw =\", M_RAW, \"| shapes:\", Xtr.shape, Xva.shape, Xte.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McDTwoVU1wpg",
        "outputId": "5e065981-7fcf-4768-b321-4e85372a848e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M_raw = 39 | shapes: (10073978, 39) (2158123, 39) (2158079, 39)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= Train function =========\n",
        "# !pip -q install lightgbm scikit-learn matplotlib pyarrow\n",
        "import time, json, matplotlib.pyplot as plt, lightgbm as lgb\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_fscore_support\n",
        "\n",
        "def per_class_recall(y_true, y_pred):\n",
        "    p, r, f, s = precision_recall_fscore_support(y_true, y_pred, average=None, zero_division=0)\n",
        "    return {int(i): float(r[i]) for i in range(len(r))}\n",
        "\n",
        "def train_lgbm(Xtr, ytr, Xva, yva, *, use_goss=False, enable_efb=False, top_rate=0.1, other_rate=0.1):\n",
        "    params = dict(\n",
        "        objective=OBJECTIVE,\n",
        "        num_class=NUM_CLASS if OBJECTIVE==\"multiclass\" else None,\n",
        "        metric=[\"multi_logloss\"] if OBJECTIVE==\"multiclass\" else [\"auc\",\"binary_logloss\"],\n",
        "        boosting_type=\"goss\" if use_goss else \"gbdt\",\n",
        "        learning_rate=0.05,\n",
        "        num_leaves=64,\n",
        "        min_data_in_leaf=50,\n",
        "        max_bin=255,\n",
        "        lambda_l2=1.0,\n",
        "        feature_fraction=1.0,\n",
        "        bagging_fraction=1.0,      # GOSS 下保持 1.0\n",
        "        enable_bundle=enable_efb,  # ← EFB 开关\n",
        "        force_col_wise=True,\n",
        "        deterministic=True,\n",
        "        seed=42,\n",
        "        verbose=-1,\n",
        "        num_threads=-1,\n",
        "        two_round=True,\n",
        "        bin_construct_sample_cnt=200000,\n",
        "    )\n",
        "    if use_goss:\n",
        "        params.update(dict(top_rate=top_rate, other_rate=other_rate))\n",
        "\n",
        "    dtr = lgb.Dataset(Xtr, ytr, free_raw_data=False)\n",
        "    dva = lgb.Dataset(Xva, yva, reference=dtr, free_raw_data=False)\n",
        "\n",
        "    # ==== 用回调实现早停 & 打印日志（兼容 v3/v4） ====\n",
        "    callbacks = []\n",
        "    if hasattr(lgb, \"early_stopping\"):\n",
        "        callbacks.append(lgb.early_stopping(stopping_rounds=100, verbose=True))\n",
        "    if hasattr(lgb, \"log_evaluation\"):\n",
        "        callbacks.append(lgb.log_evaluation(period=50))\n",
        "\n",
        "    t0 = time.time()\n",
        "    booster = lgb.train(\n",
        "    params, dtr,\n",
        "    num_boost_round=3000,                         # 给个上限：3000（或 2500）\n",
        "    valid_sets=[dtr, dva],\n",
        "    valid_names=[\"train\", \"val\"],\n",
        "    callbacks=[\n",
        "        lgb.early_stopping(stopping_rounds=50, first_metric_only=True, verbose=True),\n",
        "        lgb.log_evaluation(period=25),\n",
        "    ],\n",
        ")\n",
        "    elapsed = time.time() - t0\n",
        "\n",
        "    # 兼容式取得 best_iteration（v3/v4）\n",
        "    best_it = getattr(booster, \"best_iteration\", None)\n",
        "\n",
        "    # 计算验证集 macro-F1 作为摘要\n",
        "    proba = booster.predict(Xva, num_iteration=best_it)\n",
        "    yhat  = proba.argmax(1) if OBJECTIVE==\"multiclass\" else (proba >= 0.5).astype(int)\n",
        "    macro_f1 = f1_score(yva, yhat, average=\"macro\" if OBJECTIVE==\"multiclass\" else \"binary\")\n",
        "\n",
        "    return booster, dict(\n",
        "        time_sec=float(elapsed),\n",
        "        best_iter=int(best_it if best_it is not None else 0),\n",
        "        macro_f1=float(macro_f1),\n",
        "        n_features_input=int(Xtr.shape[1]),\n",
        "        n_features_effective=len(booster.feature_name()),\n",
        "    )\n",
        "    Xtr = pd.read_parquet(f\"{DATA_DIR}/train.parquet\"); ytr = Xtr.pop(\"label\").values\n",
        "Xva = pd.read_parquet(f\"{DATA_DIR}/val.parquet\");   yva = Xva.pop(\"label\").values\n",
        "Xte = pd.read_parquet(f\"{DATA_DIR}/test.parquet\");  yte = Xte.pop(\"label\").values\n",
        "\n",
        "with open(f\"{DATA_DIR}/ciciot2023_split_meta.json\",\"r\") as f:\n",
        "    meta = json.load(f)\n",
        "class_names = meta[\"class_names\"]\n",
        "OBJECTIVE   = \"multiclass\" if meta[\"task_mode\"]==\"multiclass\" else \"binary\"\n",
        "NUM_CLASS   = len(class_names) if OBJECTIVE==\"multiclass\" else None\n",
        "\n",
        "# >>> 新增：把字符串标签映射为整数 <<<\n",
        "import numpy as np\n",
        "if OBJECTIVE == \"multiclass\":\n",
        "    label2id = {c:i for i,c in enumerate(class_names)}\n",
        "else:\n",
        "    # 二分类时确保 0/1；按 class_names 的顺序来（比如 ['Attack','Benign']）\n",
        "    label2id = {class_names[0]:0, class_names[1]:1}\n",
        "\n",
        "ytr = np.array([label2id[s] for s in ytr], dtype=np.int32)\n",
        "yva = np.array([label2id[s] for s in yva], dtype=np.int32)\n",
        "yte = np.array([label2id[s] for s in yte], dtype=np.int32)\n",
        "\n",
        "# （可选安全检查：确保特征没有 object 列）\n",
        "for df in (Xtr, Xva, Xte):\n",
        "    obj_cols = df.select_dtypes(include=[\"object\"]).columns\n",
        "    if len(obj_cols):\n",
        "        df[obj_cols] = df[obj_cols].apply(pd.to_numeric, errors=\"coerce\").fillna(0.0).astype(\"float32\")\n",
        "\n",
        "M_RAW = Xtr.shape[1]\n",
        "print(\"M_raw =\", M_RAW, \"| shapes:\", Xtr.shape, Xva.shape, Xte.shape)\n",
        "print(\"classes -> id:\", label2id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obSEoJlv1xWB",
        "outputId": "05de3bf3-9c56-4de1-a235-7fc2eb3ca240"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M_raw = 39 | shapes: (10073978, 39) (2158123, 39) (2158079, 39)\n",
            "classes -> id: {'Backdoor_Malware': 0, 'Benign_Final': 1, 'DDoS-TCP_Flood': 2, 'DDoS-UDP_Flood': 3, 'DoS-SYN_Flood': 4, 'Mirai-udpplain': 5, 'Recon-PortScan': 6, 'VulnerabilityScan': 7, 'XSS': 8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= Run (Baseline: gbdt + no EFB) =========\n",
        "USE_GOSS=False; ENABLE_EFB=False; TOP_RATE=0.1; OTHER_RATE=0.1\n",
        "SETTING_NAME = \"gbdt_noEFB\"\n",
        "\n",
        "booster, result = train_lgbm(Xtr,ytr,Xva,yva,use_goss=USE_GOSS,enable_efb=ENABLE_EFB,\n",
        "                             top_rate=TOP_RATE,other_rate=OTHER_RATE)\n",
        "proba = booster.predict(Xva, num_iteration=getattr(booster, \"best_iteration\", None))\n",
        "yhat  = proba.argmax(1) if OBJECTIVE==\"multiclass\" else (proba>=0.5).astype(int)\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, classification_report\n",
        "rec = per_class_recall(yva, yhat)\n",
        "cm  = confusion_matrix(yva, yhat).tolist()\n",
        "print(json.dumps({**result,\"setting\":SETTING_NAME}, indent=2))\n",
        "print(classification_report(yva, yhat, target_names=class_names[:len(np.unique(yva))], digits=4))\n",
        "\n",
        "# save\n",
        "import pathlib\n",
        "with open(f\"{RESULTS}/logs/{SETTING_NAME}.json\",\"w\") as f:\n",
        "    json.dump({**result,\"setting\":SETTING_NAME,\"per_class_recall\":rec,\"cm\":cm}, f, indent=2)\n",
        "booster.save_model(f\"{RESULTS}/{SETTING_NAME}.txt\")\n",
        "\n",
        "row = {\n",
        "    \"setting\": SETTING_NAME, \"time_sec\": result[\"time_sec\"], \"best_iter\": result[\"best_iter\"],\n",
        "    \"macro_f1\": result[\"macro_f1\"], \"M_raw\": result[\"n_features_input\"],\n",
        "    \"M_effective\": result[\"n_features_effective\"], \"use_goss\": USE_GOSS, \"enable_efb\": ENABLE_EFB,\n",
        "    \"top_rate\": None, \"other_rate\": None\n",
        "}\n",
        "tbl = f\"{RESULTS}/tables/efb_goss_ablation.csv\"\n",
        "pd.DataFrame([row]).to_csv(tbl, mode=\"a\", header=not pathlib.Path(tbl).exists(), index=False)\n",
        "\n",
        "# simple per-class recall bar\n",
        "plt.figure(figsize=(9,3)); plt.bar(range(len(rec)), list(rec.values()))\n",
        "plt.xticks(range(len(rec)), [class_names[i] for i in rec.keys()], rotation=45, ha='right'); plt.ylim(0,1)\n",
        "plt.title(f\"Per-class Recall: {SETTING_NAME}\"); plt.tight_layout()\n",
        "plt.savefig(f\"{RESULTS}/figures/recall_{SETTING_NAME}.png\", dpi=150); plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "id": "VLwDZ3gF10Z8",
        "outputId": "b307af94-9666-47c4-da41-9ae42e4b99e9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n",
            "[50]\ttrain's multi_logloss: 0.060194\tval's multi_logloss: 0.0605994\n",
            "[100]\ttrain's multi_logloss: 0.0441392\tval's multi_logloss: 0.0450515\n",
            "[150]\ttrain's multi_logloss: 0.0425168\tval's multi_logloss: 0.043856\n",
            "[200]\ttrain's multi_logloss: 0.0416202\tval's multi_logloss: 0.0433623\n",
            "[250]\ttrain's multi_logloss: 0.0409627\tval's multi_logloss: 0.0430776\n",
            "[300]\ttrain's multi_logloss: 0.0403971\tval's multi_logloss: 0.0428449\n",
            "[350]\ttrain's multi_logloss: 0.0398711\tval's multi_logloss: 0.0426485\n",
            "[400]\ttrain's multi_logloss: 0.0394225\tval's multi_logloss: 0.0425075\n",
            "[450]\ttrain's multi_logloss: 0.038996\tval's multi_logloss: 0.0423834\n",
            "[500]\ttrain's multi_logloss: 0.0385974\tval's multi_logloss: 0.0422696\n",
            "[550]\ttrain's multi_logloss: 0.0382419\tval's multi_logloss: 0.0421821\n",
            "[600]\ttrain's multi_logloss: 0.0379308\tval's multi_logloss: 0.0421218\n",
            "[650]\ttrain's multi_logloss: 0.0376041\tval's multi_logloss: 0.0420602\n",
            "[700]\ttrain's multi_logloss: 0.0372909\tval's multi_logloss: 0.0420005\n",
            "[750]\ttrain's multi_logloss: 0.0369927\tval's multi_logloss: 0.0419548\n",
            "[800]\ttrain's multi_logloss: 0.036705\tval's multi_logloss: 0.0419132\n",
            "[850]\ttrain's multi_logloss: 0.0364372\tval's multi_logloss: 0.0418747\n",
            "[900]\ttrain's multi_logloss: 0.0361584\tval's multi_logloss: 0.0418373\n",
            "[950]\ttrain's multi_logloss: 0.0359272\tval's multi_logloss: 0.0418152\n",
            "[1000]\ttrain's multi_logloss: 0.0356909\tval's multi_logloss: 0.041798\n",
            "[1050]\ttrain's multi_logloss: 0.0354594\tval's multi_logloss: 0.0417762\n",
            "[1100]\ttrain's multi_logloss: 0.0352383\tval's multi_logloss: 0.0417602\n",
            "[1150]\ttrain's multi_logloss: 0.0350199\tval's multi_logloss: 0.0417434\n",
            "[1200]\ttrain's multi_logloss: 0.0348122\tval's multi_logloss: 0.041733\n",
            "[1250]\ttrain's multi_logloss: 0.0346181\tval's multi_logloss: 0.0417297\n",
            "[1300]\ttrain's multi_logloss: 0.0344221\tval's multi_logloss: 0.041717\n",
            "[1350]\ttrain's multi_logloss: 0.0342344\tval's multi_logloss: 0.0417072\n",
            "[1400]\ttrain's multi_logloss: 0.0340513\tval's multi_logloss: 0.0416975\n",
            "[1450]\ttrain's multi_logloss: 0.0338842\tval's multi_logloss: 0.0417021\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1377359104.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mSETTING_NAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gbdt_noEFB\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m booster, result = train_lgbm(Xtr,ytr,Xva,yva,use_goss=USE_GOSS,enable_efb=ENABLE_EFB,\n\u001b[0m\u001b[1;32m      6\u001b[0m                              top_rate=TOP_RATE,other_rate=OTHER_RATE)\n\u001b[1;32m      7\u001b[0m \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"best_iteration\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-659284437.py\u001b[0m in \u001b[0;36mtrain_lgbm\u001b[0;34m(Xtr, ytr, Xva, yva, use_goss, enable_efb, top_rate, other_rate)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     booster = lgb.train(\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mdtr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36meval_train\u001b[0;34m(self, feval)\u001b[0m\n\u001b[1;32m   4406\u001b[0m             \u001b[0mList\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_higher_better\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4407\u001b[0m         \"\"\"\n\u001b[0;32m-> 4408\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inner_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_data_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4410\u001b[0m     def eval_valid(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[0;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[1;32m   5183\u001b[0m             \u001b[0mtmp_out_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5184\u001b[0m             _safe_call(\n\u001b[0;32m-> 5185\u001b[0;31m                 _LIB.LGBM_BoosterGetEval(\n\u001b[0m\u001b[1;32m   5186\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5187\u001b[0m                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}